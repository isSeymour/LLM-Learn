
# 📲 LLM学习路径

## 第一部分：模型算法基础

### 编程基础

- **Web框架：**
  - 学习 **Gradio** 和 **Streamlit**，快速构建前端页面。
  - 传统 GUI 框架如 Tkinter 已少用，开发多用 C/C++/C#。

- **数据分析与可视化：**
  - 熟悉 **Pandas**、**Matplotlib**、**Seaborn**，Python 数学库用得少。

- **数据库：**
  - 掌握 Redis、PostgreSQL、MySQL、MongoDB。

- **协议与服务部署：**
  - 了解 **RESTful API**、**WebSocket**、**gRPC**，用于模型服务化。

- **并发与并行编程：**
  - 学习 **异步编程**、**多线程**、**多进程**，提升程序性能。

- **C++编程：**
  - C++ 难度大，入门慢，可做拓展学习，也可考虑 **Go**、**JS**、**Rust**。

## 第二部分：机器学习

### 基础概念和算法

- **数据工程与特征工程：**
  - 数据和特征是模型的基础，重要性不言而喻。

- **经典算法：**
  - 学习线性回归、逻辑回归、SVM、朴素贝叶斯、随机森林、K-Means、PCA 降维。

- **现代机器学习算法：**
  - 重点学习 **XGBoost**、**LightGBM**、**CatBoost** 等流行算法。

- **自动机器学习 (AutoML)：**
  - 关注 **AutoML**，自动化模型学习和参数调优。

- **模型评价指标：**
  - 掌握 **F1-score**、**准确率**、**召回率**，这些指标在评估模型中很重要。

## 第三部分：深度学习

### 深度学习基础

- **理论基础：**
  - 理解神经网络、梯度反向传播、激活函数，学习 CNN、LSTM 等结构。

- **深度学习框架：**
  - 推荐学习 **PyTorch**，更受欢迎且与 TensorFlow 2.x 类似，计算图已废弃。

- **分布式训练：**
  - 分布式训练在大模型中应用广泛，需重点学习。

## 第四部分：自然语言处理 (NLP)

### 自然语言处理的基础

- **传统 NLP 方法：**
  - 了解马尔科夫链、CRF 等传统方法。

- **预训练模型：**
  - 重点学习 **Transformer**、**BERT**、**GPT** 及其变种。

## 第五部分：大规模语言模型 (LLM)

### 大模型的基础与应用

- **主流大模型：**
  - 了解 **LLaMA**、**ChatGLM**、**Qwen**、**OpenAI** 等大模型。

- **提示工程 (Prompt Engineering)：**
  - 设计和优化提示词，提高生成效果。

- **大模型的微调和预训练：**
  - 使用 **LLaMA-Factory** 工具，学习大模型微调和预训练。

- **大模型的量化：**
  - 学习量化技术，提升模型运行效率。

- **模型部署：**
  - 了解云端和本地部署方式，如 **llama.cpp** (低性能场景) 和 **vllm** (高并发场景)。

- **模型和数据平台：**
  - 熟悉 **Hugging Face**、**ModelScope** 等平台，用于模型管理和数据共享。

- **AI Agent：**
  - 了解 AI Agent 的概念及其应用，尤其是功能调用与第三方应用结合。

- **大模型性能评测：**
  - 掌握大模型性能评测的关键指标和方法。
